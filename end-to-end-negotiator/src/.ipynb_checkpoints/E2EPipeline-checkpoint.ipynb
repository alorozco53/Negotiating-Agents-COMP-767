{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-To-End Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import re\n",
    "import random\n",
    "import utils\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import domain\n",
    "import pandas as pd\n",
    "\n",
    "from torch import optim\n",
    "from torch import autograd\n",
    "from ipywidgets import interact\n",
    "from agent import *\n",
    "from utils import ContextGenerator\n",
    "from dialog import Dialog, DialogLogger\n",
    "from models.rnn_model import RnnModel\n",
    "from models.latent_clustering_model import LatentClusteringPredictionModel, BaselineClusteringModel\n",
    "from agent import RnnAgent, RnnRolloutAgent, RlAgent, HierarchicalAgent\n",
    "from domain import get_domain\n",
    "from nltk import ngrams\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agent_type(model, smart=False):\n",
    "    if isinstance(model, LatentClusteringPredictionModel):\n",
    "        if smart:\n",
    "            return LatentClusteringRolloutAgent\n",
    "        else:\n",
    "            return LatentClusteringAgent\n",
    "    elif isinstance(model, RnnModel):\n",
    "        if smart:\n",
    "            return RnnRolloutAgent\n",
    "        else:\n",
    "            return RnnAgent\n",
    "    elif isinstance(model, BaselineClusteringModel):\n",
    "        if smart:\n",
    "            return BaselineClusteringRolloutAgent\n",
    "        else:\n",
    "            return BaselineClusteringAgent\n",
    "    else:\n",
    "        assert False, 'unknown model type: %s' % (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments:\n",
    "    alice_model_file = 'rnn_model.th'\n",
    "    alice_forward_model_file = ''\n",
    "    bob_model_file = 'rnn_model.th'\n",
    "    bob_forward_model_file = ''\n",
    "    context_file = 'data/negotiate/selfplay.txt'\n",
    "    temperature = 0.5\n",
    "    pred_temperature =1.0\n",
    "    verbose = False\n",
    "    seed = 1\n",
    "    score_threshold = 6\n",
    "    max_turns = 20\n",
    "    log_file = ''\n",
    "    smart_alice = False\n",
    "    diverse_alice = False\n",
    "    rollout_bsz = 3\n",
    "    rollout_count_threshold = 3\n",
    "    smart_bob = False\n",
    "    selection_model_file = 'selection_model.th'\n",
    "    rollout_model_file = ''\n",
    "    diverse_bob = False\n",
    "    cuda = True\n",
    "    domain = 'object_division'\n",
    "    visual = False\n",
    "    eps = 0.0\n",
    "    data = 'data/negotiate'\n",
    "    unk_threshold = 20\n",
    "    bsz = 16\n",
    "    validate = False\n",
    "    ref_text = ''\n",
    "    rl_lr = 0.002\n",
    "    rl_clip = 2.0\n",
    "    lr = 0.1\n",
    "    gamma = 0.99\n",
    "    eps = 0.5\n",
    "    clip = 0.1\n",
    "    momentum = 0.1\n",
    "    sep_sel = True\n",
    "    unk_threshold = 20\n",
    "    sv_train_freq = 1\n",
    "    \n",
    "args = Arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.use_cuda(args.cuda)\n",
    "utils.set_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml/aorozc2/anaconda3/envs/rlenv/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/ml/aorozc2/anaconda3/envs/rlenv/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.GRU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/ml/aorozc2/anaconda3/envs/rlenv/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "alice_model = utils.load_model(args.alice_model_file)\n",
    "alice_ty = get_agent_type(alice_model, args.smart_alice)\n",
    "alice = alice_ty(alice_model, args, name='Alice', train=True, diverse=args.diverse_alice)\n",
    "alice.vis = args.visual\n",
    "\n",
    "bob_model = utils.load_model(args.bob_model_file)\n",
    "bob_ty = get_agent_type(bob_model, args.smart_bob)\n",
    "bob = bob_ty(bob_model, args, name='Bob', train=False, diverse=args.diverse_bob)\n",
    "bob.vis = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "joe_model = utils.load_model(args.bob_model_file)\n",
    "joe_ty = get_agent_type(bob_model, args.smart_bob)\n",
    "joe = bob_ty(bob_model, args, name='Joe', train=False, diverse=args.diverse_bob)\n",
    "joe.vis = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset data/negotiate/train.txt, total 687919, unks 8718, ratio 1.27%\n",
      "dataset data/negotiate/val.txt, total 74653, unks 914, ratio 1.22%\n",
      "dataset data/negotiate/test.txt, total 70262, unks 847, ratio 1.21%\n"
     ]
    }
   ],
   "source": [
    "dialog = Dialog([alice, bob], args)\n",
    "logger = DialogLogger(verbose=args.verbose, log_file=args.log_file)\n",
    "ctx_gen = ContextGenerator(args.context_file)\n",
    "\n",
    "#dialog2 = Dialog([alice, joe], args)\n",
    "domain = get_domain(args.domain)\n",
    "corpus = alice_model.corpus_ty(domain, args.data, freq_cutoff=args.unk_threshold,\n",
    "                               verbose=True, sep_sel=args.sep_sel)\n",
    "engine = alice_model.engine_ty(alice_model, args)\n",
    "alice.engine = engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "validset, validset_stats = corpus.valid_dataset(args.bsz)\n",
    "trainset, trainset_stats = corpus.train_dataset(args.bsz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/tropdeep/goal-based-negotiating-agents\" target=\"_blank\">https://app.wandb.ai/tropdeep/goal-based-negotiating-agents</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/tropdeep/goal-based-negotiating-agents/runs/3o4l66wy\" target=\"_blank\">https://app.wandb.ai/tropdeep/goal-based-negotiating-agents/runs/3o4l66wy</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "W&B Run: https://app.wandb.ai/tropdeep/goal-based-negotiating-agents/runs/3o4l66wy"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(project=\"goal-based-negotiating-agents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You can only call `wandb.watch` once per model.  Pass a new instance of the model if you need to call wandb.watch again in your code.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-340bd986fd75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malice_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.7/site-packages/wandb/__init__.py\u001b[0m in \u001b[0;36mwatch\u001b[0;34m(models, criterion, log, log_freq, idx)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         graph = wandb_torch.TorchGraph.hook_torch(\n\u001b[0;32m--> 162\u001b[0;31m             model, criterion, graph_idx=global_idx)\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0mgraphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;31m# NOTE: the graph is set in run.summary by hook_torch on the backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.7/site-packages/wandb/wandb_torch.py\u001b[0m in \u001b[0;36mhook_torch\u001b[0;34m(cls, model, criterion, graph_idx)\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhook_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTorchGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m         \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhook_torch_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.7/site-packages/wandb/wandb_torch.py\u001b[0m in \u001b[0;36mhook_torch_modules\u001b[0;34m(self, module, criterion, prefix, graph_idx)\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_wandb_watch_called\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wandb_watch_called\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             raise ValueError(\n\u001b[0;32m--> 334\u001b[0;31m                 \"You can only call `wandb.watch` once per model.  Pass a new instance of the model if you need to call wandb.watch again in your code.\")\n\u001b[0m\u001b[1;32m    335\u001b[0m         \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wandb_watch_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You can only call `wandb.watch` once per model.  Pass a new instance of the model if you need to call wandb.watch again in your code."
     ]
    }
   ],
   "source": [
    "wandb.watch(alice_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc29512bfd04f5296433ea573e94035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4086), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "rew_freq = 2\n",
    "all_rewards = []\n",
    "norm_reward = 0\n",
    "args.sv_train_freq = 1\n",
    "args.verbose = False\n",
    "utt_reward = 0\n",
    "for ctxs in tqdm(ctx_gen.iter(), total=len(ctx_gen.ctxs)):\n",
    "    if args.sv_train_freq > 0 and n % args.sv_train_freq == 0:\n",
    "        batch = random.choice(trainset)\n",
    "        engine.model.train()\n",
    "        out, loss = engine.train_batch(batch, reward=utt_reward)\n",
    "        engine.model.eval()\n",
    "        wandb.log({\"loss\": loss})\n",
    "    if n % rew_freq == 0:\n",
    "        logger.dump('=' * 80)\n",
    "        conv, agree, rewards = dialog.run(ctxs, logger)\n",
    "        #dialog2.run(ctxs, logger)\n",
    "        logger.dump('=' * 80)\n",
    "        logger.dump('')\n",
    "        \n",
    "        # compute context rewards\n",
    "        reward, partner_reward = rewards\n",
    "        diff = reward - partner_reward\n",
    "        all_rewards.append(diff)\n",
    "        r = (diff - np.mean(all_rewards)) / max(1e-4, np.std(all_rewards))\n",
    "        g = r\n",
    "        rewards = []\n",
    "        for _ in alice.logprobs:\n",
    "            rewards.append(g)\n",
    "            g = g * args.gamma\n",
    "        ctx_norm_reward = 0\n",
    "        for lp, r in zip(alice.logprobs, rewards):\n",
    "            ctx_norm_reward -= lp.item() * r\n",
    "        #print('context reward:', ctx_norm_reward)\n",
    "        \n",
    "        # compute utterance rewards\n",
    "        utt_reward = 0\n",
    "        for utterance in conv:\n",
    "            unigrams = pd.Series(ngrams(utterance, 1))\n",
    "            if len(conv) < 2:\n",
    "                utt_reward -= 0.5\n",
    "                continue\n",
    "            utt_reward += unigrams.count() - 8 if unigrams.count() < 8 else 0\n",
    "            bigrams = pd.Series(ngrams(utterance, 2))\n",
    "            utt_reward -= bigrams.value_counts().std()\n",
    "            trigrams = pd.Series(ngrams(utterance, 3))\n",
    "            utt_reward -= trigrams.value_counts().std()\n",
    "        #print('utterance reward:', utt_reward)\n",
    "        utt_reward = max(-2.0, utt_reward) * args.gamma\n",
    "        \n",
    "        # logs\n",
    "        wandb.log({'utterance-reward': utt_reward,\n",
    "                   'ctx-norm-reward': ctx_norm_reward})\n",
    "            \n",
    "               \n",
    "        #input()\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Alice : book=(count:4 value:2) hat=(count:1 value:1) ball=(count:1 value:1)\n",
      "Bob   : book=(count:4 value:1) hat=(count:1 value:6) ball=(count:1 value:0)\n",
      "--------------------------------------------------------------------------------\n",
      "Alice : i need the books and the hats <eos>\n",
      "Bob   : i need the hat <eos>\n",
      "Alice : i need the other hat to your your two my much give up <eos>\n",
      "Bob   : i need the hat and the ball <eos>\n"
     ]
    }
   ],
   "source": [
    "args.verbose = True\n",
    "ctxs = random.choice(ctx_gen.ctxs)\n",
    "logger = DialogLogger(verbose=args.verbose, log_file=args.log_file)\n",
    "dialog = Dialog([alice, bob], args)\n",
    "logger.dump('=' * 80)\n",
    "conv, agree, rewards = dialog.run(ctxs, logger)\n",
    "#dialog2.run(ctxs, logger)\n",
    "logger.dump('=' * 80)\n",
    "logger.dump('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(961.6806, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.crit(out, tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9.3905, 11.0875, 11.2919, 10.6140, 11.1170, 10.4049, 11.7149, 10.3151,\n",
       "        11.3495, 10.9880, 11.8648, 10.4176, 11.2139, 11.0625, 10.5209, 11.3971,\n",
       "        10.9805, 11.2328,     nan, 10.2620, 10.4540, 11.5460, 11.6435, 11.7716,\n",
       "        11.5797, 11.4207, 10.8836, 11.1662, 11.2781, 11.7557, 10.5368, 10.4087,\n",
       "        12.1111,     nan, 10.0322, 11.5399,     nan, 11.4545, 11.2849, 11.9719,\n",
       "        11.7945, 10.8136,  9.9752, 11.5829, 12.0881, 10.8099, 12.0942, 10.4168,\n",
       "        12.5171,  9.7051, 11.4713, 11.3777,  8.7401, 10.5852, 11.6754,     nan,\n",
       "        12.6202, 11.6134, 10.3867, 11.9602, 11.8345, 11.2651, 12.1444, 11.4711,\n",
       "        12.3260, 10.7483, 10.8352, 10.8016, 11.5828, 11.7422, 10.1615, 10.7003,\n",
       "        11.3029, 12.1950, 11.6886, 12.3887, 12.1229, 11.6933, 12.0276, 12.3525,\n",
       "        12.1193,     nan, 10.5496, 11.5089, 12.4797, 11.7544, 10.1133, 11.1836,\n",
       "        10.6005, 11.6757, 12.2564, 11.9262, 11.9199, 12.3477, 12.2010, 11.8272,\n",
       "        11.3114, 11.5742, 12.3197, 11.6950, 11.9247, 11.7941,  9.5472, 11.5219,\n",
       "            nan, 12.3380, 11.9412, 12.1953, 11.6669, 11.9299, 12.0035, 11.3129,\n",
       "        11.7333, 11.3781, 11.6283,     nan, 11.9314, 10.9088, 10.9840,     nan,\n",
       "        11.2837, 12.3543,  9.9771, 11.8396, 11.4451, 11.5822, 11.9740, 10.7027,\n",
       "         9.7435, 11.2908, 10.5166,     nan, 11.7253, 11.8941, 10.7980, 12.0018,\n",
       "        12.5226, 11.6343, 11.4673, 11.8687, 10.6388, 11.0368, 11.6054, 10.0889,\n",
       "            nan, 11.7815,     nan, 10.9699, 11.0707, 11.8977,  9.8981, 11.1186,\n",
       "        12.4649, 10.6067, 11.8057, 12.2027, 11.4226, 12.2243,     nan, 11.6820,\n",
       "            nan, 10.5708,  9.8511, 10.6573, 11.7992, 12.4673, 11.0394, 11.6673,\n",
       "        12.1405, 11.7095, 12.5169, 11.8428, 11.4921, 12.5309, 11.0428, 11.4017,\n",
       "        11.3801, 10.8757,     nan,  9.4726, 12.5667, 12.1274,  9.6962, 11.2685,\n",
       "        11.7858, 11.2750, 12.3660, 12.2008, 11.8289, 12.2479,  9.7218,     nan,\n",
       "         9.8071,     nan,     nan,  8.4286, 12.1266, 11.3219, 11.5611, 11.5877,\n",
       "        11.9532, 12.4156, 12.1055, 11.2268, 11.7037, 11.9733, 11.3122,     nan,\n",
       "        10.3979, 11.6227, 11.4721, 12.0149, 10.7969, 10.5962,  8.6851,  9.7742,\n",
       "        10.2175, 12.0016, 11.5780, 11.9186,  9.4862, 12.2454,  8.8678,     nan,\n",
       "            nan, 12.2144,     nan,  9.5185, 11.1498, 10.4983,     nan,     nan,\n",
       "            nan, 10.9732,     nan, 12.8167, 10.9004, 11.3685, 11.5379,     nan,\n",
       "        10.6556, 11.6261, 11.1566, 11.6854, 10.9848, 10.6277,  9.5883, 11.0540,\n",
       "            nan, 12.1161,     nan, 12.7966, 11.3132, 10.6894, 11.2299,     nan,\n",
       "            nan, 10.2818, 12.1800, 12.2576, 11.6419, 12.2726,     nan,  8.9180,\n",
       "            nan, 11.2897, 10.3018, 12.2820, 11.1125, 11.0374,     nan,     nan,\n",
       "        11.0871, 12.0085, 12.1566, 12.4368, 12.2104, 11.6172, 10.8314, 10.8161,\n",
       "         8.4983, 11.5408, 10.7850, 11.9458,  9.1905, 11.6383,     nan,     nan,\n",
       "            nan, 12.5521, 12.1958, 11.5740, 11.5871, 10.6959,     nan, 11.9500,\n",
       "         9.6963, 11.0731, 11.2585,  9.9526, 10.2675, 11.4622,  9.8749, 11.4355,\n",
       "            nan, 12.2060, 11.8242, 11.7130, 10.9793, 11.3554, 10.7629, 11.3169,\n",
       "            nan, 10.9072, 10.9220, 12.2179,     nan, 11.5968,     nan, 11.9179,\n",
       "            nan, 10.6693, 11.4369, 10.7611, 11.9119,  5.7309, 11.4038, 11.5241,\n",
       "         8.4779,  9.9441, 10.2664, 10.9512,     nan, 10.7009, 10.6081, 11.7765,\n",
       "            nan, 11.0342, 11.7306, 10.6129, 11.6450, 10.3447,  9.1458, 11.4023,\n",
       "        11.6029, 10.6068,  9.0934, 11.3842,     nan, 11.8911,  9.3216, 11.2889,\n",
       "        11.4096, 10.2742, 12.0544, 10.8304, 11.1759, 11.7990, 10.4722, 11.1021,\n",
       "        12.0102, 11.3299,  9.7607,  8.8636, 11.3176, 11.0963,     nan, 10.5660,\n",
       "        10.5781, 11.2971, 10.0576, 10.3791, 11.2212,     nan,     nan, 11.0218,\n",
       "        11.6607, 11.3281,     nan,     nan,  9.4734,     nan,     nan,     nan,\n",
       "            nan, 11.5142, 10.6233, 11.0344, 10.9385,  7.0096,  9.8877,     nan,\n",
       "        10.5442, 11.5889,     nan, 10.4193, 10.9451,     nan,     nan,     nan,\n",
       "         8.9969, 12.2670, 11.7793, 11.9042, 11.5697,     nan, 11.5055, 11.5599,\n",
       "        11.1997, 11.7878, 11.2531,  7.7847,     nan,     nan, 11.9169, 11.2970],\n",
       "       grad_fn=<LogBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsf = nn.LogSoftmax()\n",
    "torch.log(-out @ engine.crit.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<data.Dictionary at 0x7f18f9fca5d0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice_model.word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YOU:</td>\n",
       "      <td>i'd</td>\n",
       "      <td>like</td>\n",
       "      <td>both</td>\n",
       "      <td>balls</td>\n",
       "      <td>;</td>\n",
       "      <td>maybe</td>\n",
       "      <td>a</td>\n",
       "      <td>hat</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>i</td>\n",
       "      <td>can</td>\n",
       "      <td>accept</td>\n",
       "      <td>that</td>\n",
       "      <td>one</td>\n",
       "      <td>!</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>THEM:</td>\n",
       "      <td>&lt;selection&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THEM:</td>\n",
       "      <td>i'd</td>\n",
       "      <td>like</td>\n",
       "      <td>the</td>\n",
       "      <td>hat</td>\n",
       "      <td>,</td>\n",
       "      <td>the</td>\n",
       "      <td>balls</td>\n",
       "      <td>and</td>\n",
       "      <td>a</td>\n",
       "      <td>...</td>\n",
       "      <td>deal</td>\n",
       "      <td>?</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>YOU:</td>\n",
       "      <td>no</td>\n",
       "      <td>deal</td>\n",
       "      <td>then</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>THEM:</td>\n",
       "      <td>&lt;selection&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YOU:</td>\n",
       "      <td>i'll</td>\n",
       "      <td>take</td>\n",
       "      <td>the</td>\n",
       "      <td>books</td>\n",
       "      <td>and</td>\n",
       "      <td>hat</td>\n",
       "      <td>if</td>\n",
       "      <td>you</td>\n",
       "      <td>want</td>\n",
       "      <td>...</td>\n",
       "      <td>i</td>\n",
       "      <td>take</td>\n",
       "      <td>the</td>\n",
       "      <td>books</td>\n",
       "      <td>and</td>\n",
       "      <td>1</td>\n",
       "      <td>ball</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>YOU:</td>\n",
       "      <td>&lt;selection&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YOU:</td>\n",
       "      <td>i</td>\n",
       "      <td>would</td>\n",
       "      <td>like</td>\n",
       "      <td>the</td>\n",
       "      <td>ball</td>\n",
       "      <td>,</td>\n",
       "      <td>the</td>\n",
       "      <td>hat</td>\n",
       "      <td>,</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>deal</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>THEM:</td>\n",
       "      <td>no</td>\n",
       "      <td>deal</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>YOU:</td>\n",
       "      <td>&lt;selection&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>YOU:</td>\n",
       "      <td>i'll</td>\n",
       "      <td>take</td>\n",
       "      <td>books</td>\n",
       "      <td>and</td>\n",
       "      <td>ball</td>\n",
       "      <td>,</td>\n",
       "      <td>you</td>\n",
       "      <td>can</td>\n",
       "      <td>have</td>\n",
       "      <td>...</td>\n",
       "      <td>ball</td>\n",
       "      <td>and</td>\n",
       "      <td>books</td>\n",
       "      <td>,</td>\n",
       "      <td>nothing</td>\n",
       "      <td>else</td>\n",
       "      <td>works</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>THEM:</td>\n",
       "      <td>&lt;selection&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>THEM:</td>\n",
       "      <td>would</td>\n",
       "      <td>you</td>\n",
       "      <td>accept</td>\n",
       "      <td>two</td>\n",
       "      <td>balls</td>\n",
       "      <td>?</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>YOU:</td>\n",
       "      <td>rather</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>THEM:</td>\n",
       "      <td>deal</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>YOU:</td>\n",
       "      <td>deal</td>\n",
       "      <td>!</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>THEM:</td>\n",
       "      <td>&lt;selection&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>THEM:</td>\n",
       "      <td>you</td>\n",
       "      <td>take</td>\n",
       "      <td>all</td>\n",
       "      <td>balls</td>\n",
       "      <td>and</td>\n",
       "      <td>i</td>\n",
       "      <td>keep</td>\n",
       "      <td>the</td>\n",
       "      <td>rest</td>\n",
       "      <td>...</td>\n",
       "      <td>YOU:</td>\n",
       "      <td>no</td>\n",
       "      <td>deal</td>\n",
       "      <td>,</td>\n",
       "      <td>ok</td>\n",
       "      <td>keep</td>\n",
       "      <td>talking</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>THEM:</td>\n",
       "      <td>&lt;selection&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>THEM:</td>\n",
       "      <td>how</td>\n",
       "      <td>about</td>\n",
       "      <td>2</td>\n",
       "      <td>hats</td>\n",
       "      <td>and</td>\n",
       "      <td>a</td>\n",
       "      <td>basketball</td>\n",
       "      <td>?</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>deal</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>THEM:</td>\n",
       "      <td>ok</td>\n",
       "      <td>,</td>\n",
       "      <td>sounds</td>\n",
       "      <td>good</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>YOU:</td>\n",
       "      <td>&lt;selection&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>THEM:</td>\n",
       "      <td>i'd</td>\n",
       "      <td>like</td>\n",
       "      <td>both</td>\n",
       "      <td>balls</td>\n",
       "      <td>;</td>\n",
       "      <td>maybe</td>\n",
       "      <td>a</td>\n",
       "      <td>hat</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>i</td>\n",
       "      <td>can</td>\n",
       "      <td>accept</td>\n",
       "      <td>that</td>\n",
       "      <td>one</td>\n",
       "      <td>!</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>YOU:</td>\n",
       "      <td>&lt;selection&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>THEM:</td>\n",
       "      <td>i</td>\n",
       "      <td>would</td>\n",
       "      <td>like</td>\n",
       "      <td>the</td>\n",
       "      <td>hat</td>\n",
       "      <td>and</td>\n",
       "      <td>the</td>\n",
       "      <td>balls</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>THEM:</td>\n",
       "      <td>:</td>\n",
       "      <td>-</td>\n",
       "      <td>)</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>YOU:</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>THEM:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>YOU:</td>\n",
       "      <td>could</td>\n",
       "      <td>i</td>\n",
       "      <td>have</td>\n",
       "      <td>the</td>\n",
       "      <td>books</td>\n",
       "      <td>and</td>\n",
       "      <td>a</td>\n",
       "      <td>one</td>\n",
       "      <td>hat</td>\n",
       "      <td>...</td>\n",
       "      <td>get</td>\n",
       "      <td>nothing</td>\n",
       "      <td>cant</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>books</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>YOU:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>YOU:</td>\n",
       "      <td>i</td>\n",
       "      <td>want</td>\n",
       "      <td>all</td>\n",
       "      <td>the</td>\n",
       "      <td>balls</td>\n",
       "      <td>and</td>\n",
       "      <td>the</td>\n",
       "      <td>book</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>book</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>YOU:</td>\n",
       "      <td>1</td>\n",
       "      <td>book</td>\n",
       "      <td>,</td>\n",
       "      <td>2</td>\n",
       "      <td>balls</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>THEM:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>YOU:</td>\n",
       "      <td>hello</td>\n",
       "      <td>i</td>\n",
       "      <td>would</td>\n",
       "      <td>like</td>\n",
       "      <td>the</td>\n",
       "      <td>ball</td>\n",
       "      <td>,</td>\n",
       "      <td>the</td>\n",
       "      <td>hat</td>\n",
       "      <td>...</td>\n",
       "      <td>it</td>\n",
       "      <td>seems</td>\n",
       "      <td>we</td>\n",
       "      <td>have</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>an</td>\n",
       "      <td>impasse</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>THEM:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>YOU:</td>\n",
       "      <td>hi</td>\n",
       "      <td>i</td>\n",
       "      <td>would</td>\n",
       "      <td>like</td>\n",
       "      <td>the</td>\n",
       "      <td>hat</td>\n",
       "      <td>and</td>\n",
       "      <td>books</td>\n",
       "      <td>and</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>some</td>\n",
       "      <td>lose</td>\n",
       "      <td>some</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>THEM:</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>YOU:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>THEM:</td>\n",
       "      <td>i</td>\n",
       "      <td>need</td>\n",
       "      <td>the</td>\n",
       "      <td>2</td>\n",
       "      <td>hats</td>\n",
       "      <td>,</td>\n",
       "      <td>and</td>\n",
       "      <td>1</td>\n",
       "      <td>ball</td>\n",
       "      <td>...</td>\n",
       "      <td>,</td>\n",
       "      <td>i</td>\n",
       "      <td>will</td>\n",
       "      <td>take</td>\n",
       "      <td>the</td>\n",
       "      <td>hat</td>\n",
       "      <td>and</td>\n",
       "      <td>ball</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>YOU:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>YOU:</td>\n",
       "      <td>i</td>\n",
       "      <td>could</td>\n",
       "      <td>use</td>\n",
       "      <td>a</td>\n",
       "      <td>book</td>\n",
       "      <td>a</td>\n",
       "      <td>hat</td>\n",
       "      <td>and</td>\n",
       "      <td>a</td>\n",
       "      <td>...</td>\n",
       "      <td>the</td>\n",
       "      <td>rest</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>YOU:</td>\n",
       "      <td>ok</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>THEM:</td>\n",
       "      <td>deal</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>YOU:</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows Ã— 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1      2       3      4      5      6           7      8    \\\n",
       "0    YOU:    i'd   like    both  balls      ;  maybe           a    hat   \n",
       "1   THEM:    i'd   like     the    hat      ,    the       balls    and   \n",
       "2    YOU:   i'll   take     the  books    and    hat          if    you   \n",
       "3    YOU:      i  would    like    the   ball      ,         the    hat   \n",
       "4    YOU:   i'll   take   books    and   ball      ,         you    can   \n",
       "5   THEM:  would    you  accept    two  balls      ?       <eos>   YOU:   \n",
       "6   THEM:    you   take     all  balls    and      i        keep    the   \n",
       "7   THEM:    how  about       2   hats    and      a  basketball      ?   \n",
       "8   THEM:    i'd   like    both  balls      ;  maybe           a    hat   \n",
       "9   THEM:      i  would    like    the    hat    and         the  balls   \n",
       "10   YOU:  could      i    have    the  books    and           a    one   \n",
       "11   YOU:      i   want     all    the  balls    and         the   book   \n",
       "12   YOU:  hello      i   would   like    the   ball           ,    the   \n",
       "13   YOU:     hi      i   would   like    the    hat         and  books   \n",
       "14  THEM:      i   need     the      2   hats      ,         and      1   \n",
       "15   YOU:      i  could     use      a   book      a         hat    and   \n",
       "\n",
       "       9    ...    97       98     99      100      101     102      103  \\\n",
       "0        .  ...      -        i    can  accept     that     one        !   \n",
       "1        a  ...   deal        ?  <eos>    YOU:       no    deal     then   \n",
       "2     want  ...      i     take    the   books      and       1     ball   \n",
       "3        ,  ...     no     deal      .   <eos>    THEM:      no     deal   \n",
       "4     have  ...   ball      and  books       ,  nothing    else    works   \n",
       "5   rather  ...  <eos>    THEM:   deal   <eos>     YOU:    deal        !   \n",
       "6     rest  ...   YOU:       no   deal       ,       ok    keep  talking   \n",
       "7    <eos>  ...   deal    <eos>  THEM:      ok        ,  sounds     good   \n",
       "8        .  ...      -        i    can  accept     that     one        !   \n",
       "9    <eos>  ...  THEM:        :      -       )    <eos>    YOU:    <unk>   \n",
       "10     hat  ...    get  nothing   cant   <unk>        3   books    <unk>   \n",
       "11   <eos>  ...   book    <eos>   YOU:       1     book       ,        2   \n",
       "12     hat  ...     it    seems     we    have    <unk>      an  impasse   \n",
       "13     and  ...      .    <unk>   some    lose     some   <eos>    THEM:   \n",
       "14    ball  ...      ,        i   will    take      the     hat      and   \n",
       "15       a  ...    the     rest  <eos>    YOU:       ok   <eos>    THEM:   \n",
       "\n",
       "      104    105          106  \n",
       "0   <eos>  THEM:  <selection>  \n",
       "1   <eos>  THEM:  <selection>  \n",
       "2   <eos>   YOU:  <selection>  \n",
       "3   <eos>   YOU:  <selection>  \n",
       "4   <eos>  THEM:  <selection>  \n",
       "5   <eos>  THEM:  <selection>  \n",
       "6   <eos>  THEM:  <selection>  \n",
       "7   <eos>   YOU:  <selection>  \n",
       "8   <eos>   YOU:  <selection>  \n",
       "9       .  <eos>        THEM:  \n",
       "10      .  <eos>         YOU:  \n",
       "11  balls  <eos>        THEM:  \n",
       "12      .  <eos>        THEM:  \n",
       "13  <unk>  <eos>         YOU:  \n",
       "14   ball  <eos>         YOU:  \n",
       "15   deal  <eos>         YOU:  \n",
       "\n",
       "[16 rows x 107 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_batch = pd.DataFrame()\n",
    "for j, col in enumerate(inpt):\n",
    "    col = corpus.word_dict.i2w(col)\n",
    "    word_batch[j] = pd.Series(col)\n",
    "\n",
    "word_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = random.choice(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.model.train()\n",
    "\n",
    "ctx, inpt, tgt, sel_tgt = batch\n",
    "ctx = Variable(ctx)\n",
    "inpt = Variable(inpt)\n",
    "tgt = Variable(tgt)\n",
    "sel_tgt = Variable(sel_tgt)\n",
    "\n",
    "out, sel_out = alice_model(inpt, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1712, 463]),\n",
       " torch.Size([1712]),\n",
       " torch.Size([96, 18]),\n",
       " torch.Size([1712]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape, tgt.shape, sel_out.shape, tgt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([6, 16]),\n",
       " torch.Size([107, 16]),\n",
       " torch.Size([1712]),\n",
       " torch.Size([96])]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda b: b.shape, batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      " i would like the ball and the books . <eos>\n",
      "number of unigrams: 10,\tnumber of bigrams: 9,\tnumber of trigrams: 8\n",
      "===================\n",
      "1\n",
      " then if i can have three balls that would like balls like a talk it`s split your make ? offer all of three books ? <eos>\n",
      "number of unigrams: 26,\tnumber of bigrams: 25,\tnumber of trigrams: 24\n",
      "===================\n",
      "2\n",
      " i need the ball and the books <eos>\n",
      "number of unigrams: 8,\tnumber of bigrams: 7,\tnumber of trigrams: 6\n",
      "===================\n",
      "3\n",
      " then no ( books ? <eos>\n",
      "number of unigrams: 6,\tnumber of bigrams: 5,\tnumber of trigrams: 4\n",
      "===================\n",
      "4\n",
      " i need the ball and the books <eos>\n",
      "number of unigrams: 8,\tnumber of bigrams: 7,\tnumber of trigrams: 6\n",
      "===================\n",
      "5\n",
      " then no no no deal no <eos>\n",
      "number of unigrams: 7,\tnumber of bigrams: 6,\tnumber of trigrams: 5\n",
      "===================\n",
      "6\n",
      " no deal <eos>\n",
      "number of unigrams: 3,\tnumber of bigrams: 2,\tnumber of trigrams: 1\n",
      "===================\n",
      "7\n",
      " both all of each my . <eos>\n",
      "number of unigrams: 7,\tnumber of bigrams: 6,\tnumber of trigrams: 5\n",
      "===================\n",
      "8\n",
      " no deal <eos>\n",
      "number of unigrams: 3,\tnumber of bigrams: 2,\tnumber of trigrams: 1\n",
      "===================\n",
      "9\n",
      " i no <eos>\n",
      "number of unigrams: 3,\tnumber of bigrams: 2,\tnumber of trigrams: 1\n",
      "===================\n",
      "10\n",
      " no deal <eos>\n",
      "number of unigrams: 3,\tnumber of bigrams: 2,\tnumber of trigrams: 1\n",
      "===================\n",
      "11\n",
      " no i can have all three my hats my then about about look got books books books books books able willing 4 rather a book and a book a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a all three hats if i agree . <eos>\n",
      "number of unigrams: 71,\tnumber of bigrams: 70,\tnumber of trigrams: 69\n",
      "===================\n",
      "12\n",
      " i would like the ball and one hat . <eos>\n",
      "number of unigrams: 10,\tnumber of bigrams: 9,\tnumber of trigrams: 8\n",
      "===================\n",
      "13\n",
      " i can the what <eos>\n",
      "number of unigrams: 5,\tnumber of bigrams: 4,\tnumber of trigrams: 3\n",
      "===================\n",
      "14\n",
      " deal <eos>\n",
      "number of unigrams: 2,\tnumber of bigrams: 1,\tnumber of trigrams: 0\n",
      "===================\n",
      "15\n",
      " no i all me all three my split <eos>\n",
      "number of unigrams: 9,\tnumber of bigrams: 8,\tnumber of trigrams: 7\n",
      "===================\n",
      "16\n",
      " deal <eos>\n",
      "number of unigrams: 2,\tnumber of bigrams: 1,\tnumber of trigrams: 0\n",
      "===================\n",
      "17\n",
      " i the no <eos>\n",
      "number of unigrams: 4,\tnumber of bigrams: 3,\tnumber of trigrams: 2\n",
      "===================\n",
      "18\n",
      " <selection>\n",
      "number of unigrams: 1,\tnumber of bigrams: 0,\tnumber of trigrams: 0\n",
      "===================\n"
     ]
    }
   ],
   "source": [
    "for i, c in enumerate(conv):\n",
    "    unigrams = pd.Series(ngrams(c, 1))\n",
    "    bigrams = pd.Series(ngrams(c, 2))\n",
    "    trigrams = pd.Series(ngrams(c, 3))\n",
    "    print(f'{i}\\n', ' '.join(c))\n",
    "    print('number of unigrams:', len(unigrams), end=',\\t')\n",
    "    print('number of bigrams:', len(bigrams), end=',\\t')\n",
    "    print('number of trigrams:', len(trigrams))\n",
    "    print('===================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlenv",
   "language": "python",
   "name": "rlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
