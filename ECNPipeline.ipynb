{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emergent Communications Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import codecs\n",
    "import time\n",
    "import argparse\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import nets\n",
    "import sampling\n",
    "import alive_sieve\n",
    "\n",
    "from torch import autograd, optim, nn\n",
    "from torch.autograd import Variable\n",
    "from ecn import State\n",
    "from nltk import bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments\n",
    "model_file = 'model_saves/model.dat'\n",
    "batch_size = 128\n",
    "test_seed = 123\n",
    "term_entropy_reg = 0.05\n",
    "utterance_entropy_reg = 0.001\n",
    "proposal_entropy_reg = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_r = np.random\n",
    "test_r = np.random.RandomState(test_seed)\n",
    "test_batches = sampling.generate_test_batches(batch_size=batch_size, num_batches=5, random_state=test_r)\n",
    "test_hashes = sampling.hash_batches(test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pool torch.Size([128, 3])\n",
      "utilities [torch.Size([128, 3]), torch.Size([128, 3])]\n",
      "N torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "for k, v in test_batches[1].items():\n",
    "    try:\n",
    "        print(k, v.shape)\n",
    "    except:\n",
    "        print(k, [e.shape for e in v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nets.AgentModel(\n",
    "    enable_comms=True,\n",
    "    enable_proposal=True,\n",
    "    term_entropy_reg=term_entropy_reg,\n",
    "    utterance_entropy_reg=utterance_entropy_reg,\n",
    "    proposal_entropy_reg=proposal_entropy_reg\n",
    ")\n",
    "model = model.cuda()\n",
    "optimizer = optim.Adam(params=model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = sampling.generate_training_batch(batch_size=batch_size,\n",
    "                                         test_hashes=test_hashes,\n",
    "                                         random_state=train_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_constr = torch.cuda\n",
    "batch_size = batch['N'].size()[0]\n",
    "s = State(**batch)\n",
    "s.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sieve = alive_sieve.AliveSieve(batch_size=batch_size, enable_cuda=True)\n",
    "\n",
    "# next two tensofrs wont be sieved, they will stay same size throughout\n",
    "# entire batch, we will update them using sieve.out_idxes[...]\n",
    "rewards = type_constr.FloatTensor(batch_size, 3).fill_(0)\n",
    "num_steps = type_constr.LongTensor(batch_size).fill_(10)\n",
    "term_matches_argmax_count = 0\n",
    "utt_matches_argmax_count = 0\n",
    "utt_stochastic_draws = 0\n",
    "num_policy_runs = 0\n",
    "prop_matches_argmax_count = 0\n",
    "prop_stochastic_draws = 0\n",
    "\n",
    "entropy_loss_by_agent = [\n",
    "    Variable(type_constr.FloatTensor(1).fill_(0)),\n",
    "    Variable(type_constr.FloatTensor(1).fill_(0))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml/aorozc2/rlproject/negotiation/emergent-comms-negotiation/nets.py:109: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(logits)\n",
      "/home/ml/aorozc2/rlproject/negotiation/emergent-comms-negotiation/nets.py:160: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(logits)\n"
     ]
    }
   ],
   "source": [
    "# Forward step\n",
    "agent = 0\n",
    "_prev_proposal = s.last_proposal\n",
    "nodes, term_a, s.m_prev, this_proposal, _entropy_loss, \\\n",
    "_term_matches_argmax_count, _utt_matches_argmax_count, _utt_stochastic_draws, \\\n",
    "_prop_matches_argmax_count, _prop_stochastic_draws = model(\n",
    "    pool=Variable(s.pool),\n",
    "    utility=Variable(s.utilities[:, agent]),\n",
    "    m_prev=Variable(s.m_prev),\n",
    "    prev_proposal=Variable(_prev_proposal),\n",
    "    testing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reward computation\n",
    "utility = s.utilities[:, agent]\n",
    "rewards_batch = type_constr.FloatTensor(batch_size, 3).fill_(0)\n",
    "reward_eligible_mask = term_a.view(batch_size).clone().byte()\n",
    "exceeded_pool, _ = ((this_proposal - s.pool) > 0).max(1)\n",
    "proposer = 1 - agent\n",
    "accepter = agent\n",
    "proposal = torch.zeros(batch_size, 2, 3).long()\n",
    "proposal[:, proposer] = this_proposal\n",
    "proposal[:, accepter] = s.pool - this_proposal\n",
    "max_utility, _ = s.utilities.max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_eligible_idxes = reward_eligible_mask.nonzero().long().view(-1)\n",
    "for b in reward_eligible_idxes:\n",
    "    raw_rewards = torch.FloatTensor(2).fill_(0)\n",
    "    for i in range(2):\n",
    "        raw_rewards[i] = s.utilities[b, i].cpu().dot(proposal[b, i].cpu())\n",
    "        # penalize linguistic variety\n",
    "        utt_bigrams = set(bigrams(s.m_prev[b].cpu()))\n",
    "        raw_rewards[i] -= len(utt_bigrams) / 15.0\n",
    "        \n",
    "\n",
    "    scaled_rewards = torch.FloatTensor(3).fill_(0)\n",
    "\n",
    "    # we always calculate the prosocial reward\n",
    "    actual_prosocial = raw_rewards.sum()\n",
    "    available_prosocial = max_utility[b].cpu().dot(s.pool[b].cpu())\n",
    "    if available_prosocial != 0:\n",
    "        scaled_rewards[2] = actual_prosocial / available_prosocial\n",
    "            \n",
    "    for i in range(2):\n",
    "        max_agent = s.utilities[b, i].cpu().dot(s.pool[b].cpu())\n",
    "        if max_agent != 0:\n",
    "            scaled_rewards[i] = raw_rewards[i] / max_agent\n",
    "\n",
    "    rewards_batch[b] = scaled_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.tensor(list(map(lambda utt: len(set(bigrams(utt.tolist()))), s.m_prev))) / 15.0\n",
    "len(set(bigrams(s.m_prev[b].cpu()))) / 15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 2, 4], device='cuda:0'), tensor([3, 2, 1]))"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.utilities[:, agent][0], proposal[:, agent][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlenv",
   "language": "python",
   "name": "rlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
